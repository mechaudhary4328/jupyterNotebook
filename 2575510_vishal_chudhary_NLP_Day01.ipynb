{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64281b3",
   "metadata": {},
   "source": [
    "# 1. What is the purpose of text preprocessing in NLP, and why is a essential before analysis?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Purpose of Text Preprocessing in NLP:\n",
    "Text preprocessing is a crucial step in Natural Language Processing (NLP) that involves cleaning and transforming raw text data into a format that can be easily understood and analyzed by machine learning algorithms. The main purposes of text preprocessing include:\n",
    "\n",
    "Noise Reduction: Remove irrelevant characters, formatting, and other elements that do not contribute to the meaning of the text.\n",
    "Normalization: Standardize text to a consistent format, such as converting all characters to lowercase.\n",
    "Tokenization: Break down text into smaller units (tokens) for analysis.\n",
    "Stemming/Lemmatization: Reduce words to their base or root form.\n",
    "Removing Stop Words: Eliminate common words that do not carry significant meaning.\n",
    "Removing Punctuation: Strip unnecessary symbols that do not contribute to the text's semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5699f05",
   "metadata": {},
   "source": [
    "# 2. Describe tokenization in NLP and explain its significance in text processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenization is the process of breaking down text into smaller units called tokens. \n",
    "These tokens can be words, phrases, sentences, or other meaningful elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee160e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mevis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'an', 'essential', 'step', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the Punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Now, you should be able to tokenize the text without any errors\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Tokenization is an essential step in NLP.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf20cf0",
   "metadata": {},
   "source": [
    "# 3. What are the differences between stemming and lemmatization in NLP? When would you choose one over the other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ede94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemming: Reduces words to their base or root form by removing suffixes. It may result in words that are not actual words.\n",
    "Lemmatization: Reduces words to their base form (lemma) using a vocabulary and morphological analysis. It produces valid words.\n",
    "Choose stemming for simplicity and speed when the application can tolerate some inaccuracy. \n",
    "Choose lemmatization for applications where word accuracy is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9486029",
   "metadata": {},
   "source": [
    "# 4. Explain the concept of stop words and their role in text preprocessing. How do they impact NLP tasks?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ce4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stop words are common words (e.g., \"and,\" \"the,\" \"is\") that are often removed during text preprocessing. They don't \n",
    "contribute much to the meaning of the text but can introduce noise. Removing stop words helps reduce dimensionality \n",
    "and focus on more meaningful terms, improving the efficiency of NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edccf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mevis\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'stop', 'words', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Now, you should be able to use the stopwords in your code\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is an example sentence with stop words.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(text)\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2577cd",
   "metadata": {},
   "source": [
    "# 5. How does the process of removing punctuation contribute to text preprocessing in NLP? What are its benefits?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing Punctuation in Text Preprocessing:\n",
    "Removing punctuation is essential to eliminate characters that do not carry significant meaning in text analysis. \n",
    "Punctuation removal helps simplify the text and ensures that machine learning models focus on relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07efbfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example sentence with punctuation\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"This is an example sentence with punctuation!\"\n",
    "text_no_punct = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(text_no_punct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24992a39",
   "metadata": {},
   "source": [
    "# 6. Discuss the importance of lowercase conversion in text preprocessing. Why is it a common step in NLP tasks?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f491df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lowercase Conversion in Text Preprocessing:\n",
    "Converting text to lowercase is a common step in text preprocessing to ensure uniformity.\n",
    "It helps in treating words with different cases as the same, reducing the complexity and improving the efficiency of NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85a2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is an example sentence.\n"
     ]
    }
   ],
   "source": [
    "text = \"This is an Example sentence.\"\n",
    "text_lowercase = text.lower()\n",
    "print(text_lowercase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c833f81",
   "metadata": {},
   "source": [
    "# 7. Explain the term \"vectorization\" concerning text data. How does techniques iko CountVectorizer contribute to text preprocessing in NLP?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorization and CountVectorizer in Text Preprocessing:\n",
    "Vectorization involves converting text data into numerical vectors that machine learning models can understand. \n",
    "CountVectorizer is a technique that represents the occurrence of words in a document as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c2eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218fb89",
   "metadata": {},
   "source": [
    "# 8. Describe the concept of normalization in NLP. Provide examples of normalization techniques used in text preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization in NLP:\n",
    "Normalization in NLP involves transforming text data to a standard format.\n",
    "It includes techniques such as stemming, lemmatization, lowercase conversion, and removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb12efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stem', 'is', 'a', 'techniqu', 'use', 'for', 'normal', 'in', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Stemming is a technique used for normalization in NLP.\"\n",
    "ps = PorterStemmer()\n",
    "tokens = word_tokenize(text)\n",
    "stemmed_tokens = [ps.stem(word) for word in tokens]\n",
    "print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e878f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
