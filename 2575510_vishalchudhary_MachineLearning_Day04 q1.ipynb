{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb515ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Data Exploration:\n",
    "\n",
    "# a. Load and explore the medical dataset using Python libraries like pandas. Describe the features, labels,\n",
    "# and the distribution of diagnoses.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd9fb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n",
      "\n",
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get basic statistics for numerical features\n",
    "numerical_stats = df.describe()\n",
    "print(numerical_stats)\n",
    "\n",
    "print()\n",
    "\n",
    "# Explore the distribution of diagnoses\n",
    "diagnosis_distribution = df['Outcome'].value_counts()\n",
    "print(diagnosis_distribution)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "531dd2df",
   "metadata": {},
   "source": [
    "2. Data Preprocessing:\n",
    "\n",
    "a. Explain the necessary data preprocessing steps for preparing the medical data. This may include handling missing values,\n",
    "normalizing or scaling features, and encoding categorical variables.\n",
    "\n",
    "Handling Missing Values: Check the dataset for missing values in each feature. Depending on the extent of missing data, you have several options:\n",
    "\n",
    "Impute missing values with the mean, median, or mode of the feature.\n",
    "Remove rows with missing values if there are only a few of them and it won't significantly impact your dataset.\n",
    "Normalization or Scaling: Normalize or scale numerical features to ensure that they have a similar scale. This is important for Naive Bayes, as it assumes that features are normally distributed. Common techniques include Min-Max scaling or Z-score normalization.\n",
    "\n",
    "Encoding Categorical Variables: If your dataset contains categorical variables (non-numeric data), you'll need to encode them into numeric format. One-hot encoding is a common method for converting categorical variables into binary (0 or 1) features.\n",
    "\n",
    "Train-Test Split: Split your dataset into a training set and a testing set. The training set is used to train your Naive Bayes model, and the testing set is used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5919f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    0.651042\n",
      "1    0.348958\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# b. Calculate the prior probabilities P(Condition) and P(No Condition) based on the class distribution.\n",
    "\n",
    "condition_prob = df['Outcome'].value_counts(normalize=True)\n",
    "print(condition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906250b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 30) (14118037.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 30\u001b[1;36m\u001b[0m\n\u001b[1;33m    interpretability is crucial for healthcare professionals to understand and trust the model's decisions.\u001b[0m\n\u001b[1;37m                                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 30)\n"
     ]
    }
   ],
   "source": [
    "# 3. Feature Engineering:\n",
    "\n",
    "# a. Describe how to convert the medical test results and patient information into suitable features for the Naive Bayes model.\n",
    "\n",
    "a. Converting Medical Test Results and Patient Information into Features:\n",
    "\n",
    "Feature Selection: Identify the relevant features that are likely to influence the medical diagnosis. Not all features in \n",
    "your dataset may be equally important. Domain knowledge and feature selection techniques can help you choose the most \n",
    "informative attributes.\n",
    "\n",
    "Categorical Variable Encoding: If your dataset contains categorical variables, you should encode them into binary \n",
    "features using techniques like one-hot encoding. For example, if you have a categorical variable like \"Gender,\" \n",
    "you can encode it into two binary features: \"IsMale\" and \"IsFemale.\"\n",
    "\n",
    "Normalization or Scaling: Normalize or scale numerical features to ensure that they have similar scales. This is \n",
    "important because the Naive Bayes algorithm assumes that features are normally distributed. Common scaling methods \n",
    "include Min-Max scaling or Z-score normalization.\n",
    "\n",
    "# b. Discuss the importance of feature selection or dimensionality reduction in medical diagnosis.\n",
    "\n",
    "b. Importance of Feature Selection or Dimensionality Reduction in Medical Diagnosis:\n",
    "\n",
    "Improved Model Performance: By selecting the most informative features and reducing dimensionality, you can create \n",
    "a more focused and accurate model. This can lead to better predictive performance.\n",
    "\n",
    "Reduced Overfitting: Models with high dimensionality are more prone to overfitting, which can result in poor \n",
    "generalization to new, unseen data. Feature selection and dimensionality reduction can help mitigate overfitting.\n",
    "\n",
    "Interpretability: Simpler models with fewer features are often more interpretable. In medical diagnosis, \n",
    "interpretability is crucial for healthcare professionals to understand and trust the model's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72669167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implementing NaÃ¯ve Bayes:\n",
    "\n",
    "# a. Choose the appropriate Naive Bayes variant (e.g., Gaussian, Multinomial, or Bernoulli Naive Bayes) for the medical\n",
    "# diagnosis task and implement the classifier using Python libraries like scikit-learn.\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Split the dataset into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define labels\n",
    "labels = df['Outcome']\n",
    "\n",
    "# Split the dataset into 70% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Outcome', axis=1), labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6dbe85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Model Training:\n",
    "\n",
    "# a. Train the Naive Bayes model using the feature-engineered dataset. Explain the probability estimation process in Naive\n",
    "# Bayes for medical diagnosis.\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6cf346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6666666666666666\n",
      "F1-Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# 6. Model Evaluation:\n",
    "\n",
    "# a. Assess the performance of the medical diagnosis model using relevant evaluation metrics, such as accuracy, precision,\n",
    "# recall, and F1-score.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
    "y_pred = [1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83da067",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2854255680.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    Accuracy: Accuracy provides an overall measure of how well the model is performing. A high accuracy indicates that the\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# b. Interpret the results and discuss the model's ability to accurately classify medical conditions.\n",
    "\n",
    "Accuracy: Accuracy provides an overall measure of how well the model is performing. A high accuracy indicates that the\n",
    "model is making correct predictions for a large portion of the dataset. However, in imbalanced datasets (where one\n",
    "class is significantly larger than the other), accuracy alone may not be a reliable indicator.\n",
    "\n",
    "Precision: Precision is crucial in medical diagnosis because it measures how well the model identifies true positives\n",
    "while minimizing false positives. High precision means that the model is accurate when it predicts a positive case.\n",
    "\n",
    "Recall: Recall is equally important, especially in cases where its crucial not to miss positive cases. High recall\n",
    "indicates that the model captures a large portion of the actual positive cases.\n",
    "\n",
    "F1-Score: The F1-score balances precision and recall. It is useful when you want a single metric that considers both false\n",
    "positives and false negatives. A higher F1-score indicates a better trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064dac06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
